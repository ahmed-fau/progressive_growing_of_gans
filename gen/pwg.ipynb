{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('gvars_g1.pkl', 'rb') as f:\n",
    "    g1_vars = pickle.load(f)\n",
    "    \n",
    "with open('gvars_g2.pkl', 'rb') as f:\n",
    "    g2_vars = pickle.load(f)\n",
    "    \n",
    "with open('snapshot_z.pkl', 'rb') as f:\n",
    "    snapshot_z = pickle.load(f)\n",
    "    \n",
    "print snapshot_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g1n_to_var = {}\n",
    "g2n_to_var = {}\n",
    "for (g1n, g1v), (g2n, g2v) in zip(g1_vars, g2_vars):\n",
    "    g1n_to_var[g1n] = g1v\n",
    "    g2n_to_var[g2n] = g2v\n",
    "    print g1n, g1v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n2v = g2n_to_var\n",
    "\n",
    "def pixel_norm(x):\n",
    "    # NOTE: axis=-1 because we're using NWC rather than NCW\n",
    "    return x / tf.sqrt(tf.reduce_mean(tf.square(x), axis=-1, keepdims=True) + 1e-8)\n",
    "\n",
    "def wscale(x, scale, bias_fn, nonlinearity):\n",
    "    return nonlinearity((x * scale) + n2v[bias_fn])\n",
    "\n",
    "def upscale(x, scale=4):\n",
    "    _, w, nch = x.get_shape().as_list()\n",
    "    \n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    x = tf.image.resize_nearest_neighbor(x, [1, w * scale])\n",
    "    x = x[:, 0]\n",
    "    \n",
    "    return x\n",
    "\n",
    "conv_filter = lambda fn: np.transpose(n2v[fn], [2, 1, 0])[::-1]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "z = tf.placeholder(tf.float32, [None, 512])\n",
    "\n",
    "z_norm = pixel_norm(z)\n",
    "\n",
    "x = tf.expand_dims(z_norm, axis=1)\n",
    "\n",
    "# Conv1 (projects latents)\n",
    "x = tf.pad(x, [[0, 0], [15, 15], [0, 0]])\n",
    "x = tf.nn.conv1d(x, conv_filter('G1a.W'), 1, padding='VALID', data_format='NWC')\n",
    "x = wscale(x, 0.015617936, 'G1aS.b', tf.nn.leaky_relu)\n",
    "x = tf.nn.conv1d(x, conv_filter('G1b.W'), 1, padding='SAME', data_format='NWC')\n",
    "x = wscale(x, 0.020833442, 'G1bS.b', tf.nn.leaky_relu)\n",
    "\n",
    "# Conv2\n",
    "x = upscale(x)\n",
    "x = tf.nn.conv1d(x, conv_filter('G2a.W'), 1, padding='SAME', data_format='NWC')\n",
    "x = wscale(x, 0.020837622, 'G2aS.b', tf.nn.leaky_relu)\n",
    "x = tf.nn.conv1d(x, conv_filter('G2b.W'), 1, padding='SAME', data_format='NWC')\n",
    "x = wscale(x, 0.020843236, 'G2bS.b', tf.nn.leaky_relu)\n",
    "\n",
    "# Conv3\n",
    "x = upscale(x)\n",
    "x = tf.nn.conv1d(x, conv_filter('G3a.W'), 1, padding='SAME', data_format='NWC')\n",
    "x = wscale(x, 0.020820292, 'G3aS.b', tf.nn.leaky_relu)\n",
    "x = tf.nn.conv1d(x, conv_filter('G3b.W'), 1, padding='SAME', data_format='NWC')\n",
    "x = wscale(x, 0.020836806, 'G3bS.b', tf.nn.leaky_relu)\n",
    "\n",
    "# Conv4\n",
    "x = upscale(x)\n",
    "x = tf.nn.conv1d(x, conv_filter('G4a.W'), 1, padding='SAME', data_format='NWC')\n",
    "x = wscale(x, 0.02082933, 'G4aS.b', tf.nn.leaky_relu)\n",
    "x = tf.nn.conv1d(x, conv_filter('G4b.W'), 1, padding='SAME', data_format='NWC')\n",
    "x = wscale(x, 0.020813614, 'G4bS.b', tf.nn.leaky_relu)\n",
    "\n",
    "# Conv5\n",
    "x = upscale(x)\n",
    "x = tf.nn.conv1d(x, conv_filter('G5a.W'), 1, padding='SAME', data_format='NWC')\n",
    "x = wscale(x, 0.020801041, 'G5aS.b', tf.nn.leaky_relu)\n",
    "x = tf.nn.conv1d(x, conv_filter('G5b.W'), 1, padding='SAME', data_format='NWC')\n",
    "x = wscale(x, 0.0294875, 'G5bS.b', tf.nn.leaky_relu)\n",
    "\n",
    "# Conv6\n",
    "x = upscale(x)\n",
    "x = tf.nn.conv1d(x, conv_filter('G6a.W'), 1, padding='SAME', data_format='NWC')\n",
    "x = wscale(x, 0.029462723, 'G6aS.b', tf.nn.leaky_relu)\n",
    "x = tf.nn.conv1d(x, conv_filter('G6b.W'), 1, padding='SAME', data_format='NWC')\n",
    "x = wscale(x, 0.04161643, 'G6bS.b', tf.nn.leaky_relu)\n",
    "\n",
    "# Aggregate\n",
    "f = np.reshape(g1n_to_var['Glod0.W'], [1, 128, 1])\n",
    "x = tf.nn.conv1d(x, f, 1, padding='VALID', data_format='NWC')\n",
    "Gz = wscale(x, 0.08200226, 'Glod0S.b', tf.identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Audio\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    _Gz = sess.run(Gz, {z: snapshot_z})\n",
    "    print _Gz[0, :, 0]\n",
    "    display(Audio(_Gz[0, :, 0], rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as wavread\n",
    "\n",
    "_, ref = wavread('fakes008400.wav')\n",
    "\n",
    "def adjust_dynamic_range(data, drange_in, drange_out):\n",
    "    if drange_in != drange_out:\n",
    "        scale = (np.float32(drange_out[1]) - np.float32(drange_out[0])) / (np.float32(drange_in[1]) - np.float32(drange_in[0]))\n",
    "        bias = (np.float32(drange_out[0]) - np.float32(drange_in[0]) * scale)\n",
    "        data = data * scale + bias\n",
    "    return data\n",
    "\n",
    "ref = np.reshape(ref, [8, -1])\n",
    "ref = ref[:, :16384]\n",
    "ref = ref.astype(np.float32)\n",
    "ref = adjust_dynamic_range(ref, [-32768, 32767], [-1, 1])\n",
    "print ref[0]\n",
    "display(Audio(ref[0], rate=16000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
